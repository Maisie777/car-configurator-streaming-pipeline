from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder \
    .appName("QueryParquetOutput") \
    .master("local[*]") \
    .getOrCreate()

# Read the output Parquet data
df = spark.read.parquet("output_samples/parquet")

# Register temporary view for SQL queries
df.createOrReplaceTempView("config_events")

# 1Ô∏è‚É£ Most popular car models
print("üîç Most Popular Car Models:")
spark.sql("""
    SELECT model, COUNT(*) AS event_count
    FROM config_events
    GROUP BY model
    ORDER BY event_count DESC
""").show(truncate=False)

# 2Ô∏è‚É£ Average build price by engine type
print("üí∏ Average Price by Engine:")
spark.sql("""
    SELECT engine, ROUND(AVG(price), 2) AS avg_price
    FROM config_events
    GROUP BY engine
    ORDER BY avg_price DESC
""").show(truncate=False)

# 3Ô∏è‚É£ Most selected color per model
print("üé® Top Colors Per Model:")
spark.sql("""
    SELECT model, color, COUNT(*) AS color_count
    FROM config_events
    GROUP BY model, color
    ORDER BY model, color_count DESC
""").show(truncate=False)

# 4Ô∏è‚É£ Most common configuration step
print("ü™ú Most Common Configurator Steps:")
spark.sql("""
    SELECT step, COUNT(*) AS step_count
    FROM config_events
    GROUP BY step
    ORDER BY step_count DESC
""").show(truncate=False)

# 5Ô∏è‚É£ Distribution of prices (optional: histogram buckets)
print("üìä Price Distribution Buckets:")
spark.sql("""
    SELECT 
        CASE 
            WHEN price < 70000 THEN '<70k'
            WHEN price BETWEEN 70000 AND 90000 THEN '70k‚Äì90k'
            WHEN price BETWEEN 90000 AND 110000 THEN '90k‚Äì110k'
            ELSE '>110k'
        END AS price_range,
        COUNT(*) AS count
    FROM config_events
    GROUP BY price_range
    ORDER BY price_range
""").show(truncate=False)

# Stop the Spark session
spark.stop()
